---
title: "MLW & KUHeS - R and Statistics Workshop - Introduction to R"
author: "Marc Henrion"
date: "16, 18 May & 23, 24, 30 May & 1 June 2023"
output: 
  html_document:
    toc: true
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# License

![](https://i.creativecommons.org/l/by/4.0/88x31.png)

This document and its contents are licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/).

# Session 1 - Introduction to R

## Getting started 

### R and RStudio IDE

There's 2 main parts of software that you will need.

* R is an environment for statistical computing. It is a programming language, specifically a scripting / interpreted language that does not require compilation.
  + [https://cran.r-project.org/](https://cran.r-project.org/)
  
* RStudio is a company who have developed the most used graphical user interface (GUI) / integrated development environment (IDE) for R.
  + [https://www.rstudio.com](https://www.rstudio.com)
  
R is free and open source. Most latest statistical developments are first implemented in R. Unlike commercial packages (SAS, Stata, ...), there is little to no quality control for R packages other than feedback from users. Be aware of this!

You will mostly interact with R through RStudio, so familiarise yourself with the interface:

![RStudio interace](dataAndSupportDocs/rstudio.png)

### Resources

* R help files

  + Type `?` followed by the name of the command you want to get help on.
  + Type `help.start()` to open manuals, FAQs and other material.

* CRAN

  + Tutorials & manuals: [https://cran.r-project.org/manuals.html](https://cran.r-project.org/manuals.html)
  + Task views: [https://cran.r-project.org/web/views/](https://cran.r-project.org/web/views/)

* RStudio

  + Cheatsheets: [https://rstudio.com/resources/cheatsheets/](https://rstudio.com/resources/cheatsheets/)

* Text books

  + Many, but this one is excellent and free: [http://r4ds.had.co.nz](http://r4ds.had.co.nz)
 
* Online tutorials, blogs, forums

  + Why R? webinars [http://whyr.pl/foundation/webinars/](http://whyr.pl/foundation/webinars/)
  + R-bloggers [https://www.r-bloggers.com/](https://www.r-bloggers.com/)
  + Stack overflow [https://stackoverflow.com/questions/tagged/r](https://stackoverflow.com/questions/tagged/r)
  + R Graph Gallery [https://www.r-graph-gallery.com/](https://www.r-graph-gallery.com/)
  + Data Camp [https://www.datacamp.com/](https://www.datacamp.com/)


### R packages

R is stand-alone and you can code any functions you need for your analysis. But why re-invent the wheel, when others have already done this? This is where R packages come in: they are sets of R functions and data that you can load to access specific functions, models etc. In fact, a standard installation of R comes with 15 core and 15 recommended packages:

* **Base**: base, compiler, datasets, graphics, grDevices, grid, methods, parallel, splines, stats, stats4, tcltk, tools, translations, utils
* **Recommended**: KernSmooth, MASS, Matrix, boot, class, cluster, codetools, foreign, lattice, mgcv, nlme, nnet, rpart, spatial, survival

Packages are hosted either on the **C**omprehensive **R** **A**rchive **N**etwork (CRAN, [https://cran.r-project.org](https://cran.r-project.org)) or on Bioconductor ([https://bioconductor.org](https://bioconductor.org)). CRAN is the most commonly used of these with Bioconductor packages mostly targeted at bioinformaticians.

You install packages from CRAN by using the `install.packages()` function.

For example:

```{r install, eval=F}
install.packages("tidyverse")
install.packages("lubridate")
```

And you load packages by using the function `library()`, for example:

```{r libraries}
library(tidyverse)
library(lubridate)
library(gridExtra)
```

Installation details for Bioconductor pacakges are given on the Bioconductor website for each package (see e.g. [https://bioconductor.org/packages/release/bioc/html/variancePartition.html](https://bioconductor.org/packages/release/bioc/html/variancePartition.html)).


## Reading and writing data

As the most basic task for any analysis in R, you need to be able to read your data into R and, at the end, write the results to a file on your har drive.

Let's start by using some data that R comes with, write it out to the disk, then read it back in. The dataset `iris` is a famous dataset recording 150 observations of 3 species of flowers. It was extensively used by Ronald Fisher as he developed his statistical theory. Find out more about the data by typing `?iris` at the R console.

### Working directory

R has a **working directory**, this is the directory on your computer that you are working from. Unless you give full, absolute paths to files, all paths and filenames will be relative to this path.

You can find out the current working directory with the `getwd()` function:

```{r}
getwd()
```

And you can set it using the `setwd()` command. Note that R requires, even on Windows machines, forward slashes not backward slashes (i.e. `"C:/Users/marc/Documents"` not `"C:\Users\marc\Documents"`).

```{r, eval=F}
setwd("C:/Users/marc/Documents/")
```

### Writing data to disk

We will use `iris` which is a data frame of 150 rows and 5 columns (variables `Sepal.Length`, `Sepal.Width`, `Petal.Width`, `Species`). If you want to see another way of storing the same data, have a look at `iris3` - a 3-dimensional array.

```{r datWrite}
head(iris)
dim(iris)
table(iris$Species)
```

Now, let's write this as a comma-separated file (we first create a sub-directory to put our files in):

```{r datWrite2}
dir.create("dataAndSupportDocs",showWarnings=FALSE) # creates a directory in your current working directory
write.csv(iris,file="dataAndSupportDocs/iris.csv",row.names=FALSE) # saves the data to a csv file
```

Check on your hard drive, you will now have a file named `iris.csv` (inside a directory named `dataAndSupportDocs`) which you can open with a text editor, Excel, ...

If you want a bit more control over how the file is written (e.g. different column separator, whether or not to include row and/or column names), you can use the more general `write.table()` function.

```{r}
write.table(iris,file="dataAndSupportDocs/iris.tab",sep="\t",row.names=FALSE) # tab separated
```

### Reading data from disk

Let's suppose now that this file is our dataset and we want to load it into R so that we can work with it. We need to read the content into memory (RAM) and assign it to an object in R that we can then manipulate or feed into different functions for analysis or visualisation. For this we use the function `read.csv()` and the assignment operator `<-`.

```{r datRead}
dat<-read.csv("dataAndSupportDocs/iris.csv")

head(dat)
dim(dat)
table(dat$Species)
```

There are alternatives: the more general function `read.table()` or the function `read_csv()` from the R package `readr` which is one package contained in  a set known as the **tidyverse**. `read_csv()` will store the data as a tibble which is a special type of data frame.

```{r datRead2}
dat2<-read.table(sep=",",header=T,file="dataAndSupportDocs/iris.csv")

head(dat2)
dim(dat2)
table(dat2$Species)

# library(tidyverse)
# tidyverse / readr package needed, else read_csv() won't be available
dat3<-read_csv("dataAndSupportDocs/iris.csv")
head(dat3)
dim(dat3)
table(dat3$Species)
```

Note above the line `# library(tidyverse)`. The hash symbol at the start means this line is a **comment**, this code will not be run and can be free text. Comments are useful to make your code more readable to others (including your future self!).
It is good practice to use comments.

Comments can also be used to skip some lines of code, which is what was done here. The comment is just to alert you to the fact that you will need to load the `tidyverse` packages for the function `read_csv()` to be available.

### Assignment operator

For the assignment operator `<-` that we used above, you can also write `=` or `->` (and reversing the left and right hand sides with that last operator), but R coders usually prefer to use `<-`. It basically means that you create an object named `dat` in you current working memory and you assign to this object what follows on the right hand side of the operator (in this case the contents of the file `iris.csv`).


## Working with data

### Data & object types

#### Data types (in general)

A variable has one of 4 levels of measurement:

* **nominal** - classifies observations into different categories
  + alive / dead
  + human, fish, goat, bird

* **ordinal** - different categories, but categories are ordered
  + low, medium, high

* **interval** - ordered data with degree of difference; ratios not meaningful
  + temperature in centigrade: difference betwen 10^o^ and 20^o^ same as between 50^o^ and 60^o^ but 20^o^ not twice as hot as 10^o^

* **ratio** - interval data with a unique, non arbitrary zero value; ratios meaningful
  + temperature in Kelvin
  + length
  
#### Data types (in R)

R supports the following data types:

* **Character**

```{r}
a<-c("male","female")
```

* **Integer**

```{r}
b<-1:4
```

* **Numeric / double**

```{r}
c<-8/11
d<-pi
```

* **Logical / boolean**

```{r}
e<-1:10 %% 2 == 0
f<-TRUE
g<-4<2
```

* **Factor / nominal**

```{r}
h<-factor(sample(a,size=20,replace=T))
```


#### Useful functions

Display data type of an object:

```{r, eval=F}
typeof()
```

Check if an object is of a certain data type:

```{r, eval=F}
is.character()
is.integer()
is.numeric()
is.logical()
is.factor()
```

Force data type change for an object:

```{r, eval=F}
as.character()
as.integer()
as.numeric()
as.logical()
as.factor()
```

#### Dates

Dates are a special type of data and require special functions to work with. By far the most helpful package is `lubridate`. It allows you to easily parse date format, using functions like `ymd()`, `ymd_hms()`, `ym()`...

See the [lubridate cheat sheet](https://github.com/rstudio/cheatsheets/raw/master/lubridate.pdf) for more information.

```{r dates}
ymd("2022-06-04")

ymd("2022 June 4")

ymd_hms("2022-06-04 10:00:00")

ym("2022-06")

ymd("2022-06-04") - ymd("2022-03-02")
```

#### Object types

* Vectors
  + A single number or word is just a vector of length 1.
  + You can create vectors with the function `c()`.
  + E.g. `v1<-c(1,2,-12.34,5/6)`
  + Shorthands for certain types of vectors, e.g. `v2<-1:10`
  + You can access individual elements of a vector, e.g. 3rd element `v1[3]`
  
* Matrices
  + Matrices hold data tables (rows and columns).
  + All elements of a matrix need to be of the same type (e.g. all numeric or all character).
  + You can create matrices with the function `matrix()`.
  + E.g. `m1<-matrix(nrow=2,byrow=TRUE,1:16)`
  + You can access individual elements of a matrix, e.g. 2nd row, 3rd column `m1[2,3]`
  
* Arrays
  + Generalise matrices to have any number of dimensions (i.e. more than just 2, e.g. 3x3x2).
  + Not used that commonly.
  + E.g. `a1<-table(mtcars$cyl,mtcars$gear,mtcars$am)`
  + You can access individual elements of an array, e.g. `a1[3,1,2]`

* Lists
  + Lists are very flexible objects that can hold several elements.
  + Each element can be of a different type.
  + Elements can (but don't need to) be named.
  + E.g. `l1<-list(wordVector=c("hello","how","are","you","?"),numberMatrix=matrix(nrow=3,1:9))`
  + You can access individual elements, e.g. first element `l1[[1]]` or by name `l1$wordVector`

* Data frames
  + This is the most common object you will use to work with data, e.g. `read.csv()` returns a data frame.
  + Data frames are like matrices in that they provide a data table (rows and columns) but unlike matrices allow different data types for different columns.
  + Technically data frames are special types of lists. This means that you can access individual columns / variables by using the `$` notation.
  + E.g. `df1<-data.frame(pid=1:5,name=c("Chimwemwe","Esther","John","Dalitso","Julie"))` or object `dat` from earlier.
  + You can access individual variables, e.g. `df1$name` or `df1[,"name"]` or `df[,2]`.
  + You can access individual rows, e.g. `df1[1,]`.
  + You can access individual elements, e.g. `df1[3,2]` or `df$name[3]`

* Tibbles
  + Tibbles are data frames, but have special methods for printing, accessing and working with them.
  + Tibbles are used by the `tidyverse` packages.
  + E.g. `read_csv()` returns a tibble.
  + Use tibbles just like data frames.
  
The rules of *tidy* data:

* 1 row = 1 observation
* 1 column = 1 variable
* 1 cell = 1 value.

### Handling data

#### Filter (observations) & select (variables)

Often you only want to work with a subset of your data. This may be that you are interested only in one group of observations or that you may want to get rid of irrelevant variables. The `dplyr` package provides 2 easy to use function for this:

* `filter()` allows filtering out only certain observations
* `select()` allows selecting specific variables

For example:

```{r eval=F}
filter(.data=iris,Species=="setosa") # returns only the observations where the Species variable is set to "setosa"
select(.data=iris,Petal.Width,Petal.Length) # returns only the Petal.Width and Petal.Length variables from the iris data frame
```

Often you want to combine these operations. For this, pipes are useful - see below.

#### Pipe operators

The `tidyverse` package `magrittr` introduced a pipe operator, `%>%`, to R. You may be familiar with pipes if you have done any shell scripting before (e.g. `bash` or `zsh` where the pipe operator is `|`). Pipes allow to transfer the output of one function as input to another function. This allows for more concise code.

Since R v4.1.0 there is also a native pipe symbol in R: `|>`.

For example:

```{r}
iris %>%
  filter(Species=="setosa") %>%
  select(Petal.Width,Petal.Length) %>%
  head(n=5)
```

```{r}
iris |>
  filter(Species=="setosa") |>
  select(Petal.Width,Petal.Length) |>
  head(n=5)
```

#### Creating new variables

You can use the function `mutate()` (add new variables and preserve existing ones) and `transmute()` (add new variables but drop existing ones) from the `dplyr` package (part of the tidyverse).

```{r}
irisNew <- iris %>%
  mutate(
    LRatio=Sepal.Length/Petal.Length,
    WRatio=Sepal.Width/Petal.Width
  )
head(irisNew)
```

```{r}
irisNew2 <- iris %>%
  transmute(
    LRatio=Sepal.Length/Petal.Length,
    WRatio=Sepal.Width/Petal.Width
  )

head(irisNew2)
```

This can also be useful to recode categorical variables; e.g. suppose we wish to change the `Species` variable in the `iris` dataset so that *virginica* and *versicolor* are combined into a single value.

```{r}
irisNew3 <- iris %>%
  mutate(
    Species=fct_recode(Species,setosa="setosa",virginica_versicolor="virginica",virginica_versicolor="versicolor")
  )

table(iris$Species)
table(irisNew3$Species)
```

Another useful situation may be when a binary or dichotomous variable is coded as 1/2 (here we assume 1=success and 2=failure) but you want it coded 0/1 (0=failure, 1=success).

```{r}
# first we create a data frame with an ID variable and a dichotomous variable, binVar, codes as 1/2
# then we use the mutate() function to create a new variable called binVar01 which will have the recoded values for variable binVar - now coded as 0/1
# the actual conversion is done using the function case_when()
df<-data.frame(
  ID=1:10,
  binVar=sample(1:2,replace=T,size=10,prob=c(0.2,0.8))
) %>%
  mutate(
    binVar01=case_when(
      binVar==2~0,
      binVar==1~1
    )
  )

table(df$binVar)
table(df$binVar01)
```

#### Join / merge data tables

At a very basic level you can use the commands `rbind()` and `cbind()` to join vectors / matrices / data frames by rows (`rbind`) or columns (`cbind`). This requires the objects getting combined to have either the same number and sae order of columns (when `rbind()` is used) or rows (for `cbind()`).


```{r}
irisRatios<-data.frame(
  LRatio=iris$Sepal.Length/iris$Petal.Length,
  WRatio=iris$Sepal.Width/iris$Petal.Width
)

irisNew3<-cbind(iris,irisRatios)

head(irisNew3)
```

```{r}
newMatrix<-rbind(1:3,4:6)
head(newMatrix)
```

However, in many situations we want to join tables of different dimensions and we want to extract some information from one data frame and add it to another. For example you may have a first data frame consisting of individual-level data on patients and which drug they were given and a second data frame consisting of data on drugs - what is the active ingredient for example. You may want to add the drug data to the individual level data based on which drug each patient received.

For such operations, **joins** are important operations. There are many ways you can join 2 data frame, depending on how you want to add information. The graphic below summarises different joins: left joins (almost always what you want to do), right joins, full joins and inner joins.

You can use the `dplyr` package functions `left_join()`, `right_join()`, `full_join()` and `inner_join()` to do such join operations.

![Wickham, H. & Grolemund G., R for Data Science, O’Reilly, 2016](dataAndSupportDocs//joins.png){height=400px}

```{r}
# Patient-level data
pDat<-data.frame(
  name=c("Marc","Ulemu","Clemens","Brigitte"),
  age=c(37,48,46,38),
  drug=c("Lariam","Lariam","Malarone","none")
)

# Drug-level data
dDat<-data.frame(
  commonName=c("Acticlate","Aralen","Jasoprim","Lariam","Malarone","Malirid","Monodox"),
  ingredient=c("Doxycycline","Chloroquine","Primaquine","Mefloquine","Atavaquone/Proguanil","Primaquine","Doxycyline")
)

# Left join
pDatWithDrug<-left_join(pDat,dDat,by=c("drug" = "commonName"))

head(pDat)
head(dDat)
head(pDatWithDrug)
```

#### Pivot data (wide $\rightarrow$ long and long $\rightarrow$ wide)

When data are collected with repeated measurements on the same unit over time or across different conditions (e.g. longitudinal patient data, or before / after data on the same patients), the data can be either in a *wide* format or a *long* format.

Depending on what analysis is going to be done, the data may need to be in either of these 2 formats. It is important to be able to switch between both formats when needed. The package `tidyr` provides 2 useful functions for this: `pivot_longer()` and `pivot_wider()`.

Their use is best illustrated with an example.

```{r}
datWide <- read.table(header=TRUE, text='
                      subject sex control cond1 cond2
                      1       M       7.9  12.3  10.7
                      2       F       6.3  10.6  11.1
                      3       F       9.5  13.1  13.8
                      4       M      11.5  13.4  12.9
                      ')
datWide$subject <- factor(datWide$subject)

print(datWide)
```

This is the *wide* format: 1 individual per row, multiple observations of the same variable under different conditions or fixed timepoints.

**Wide to long:** `pivot_longer()`

```{r, collapse=T}
datLong<-pivot_longer(datWide,cols=c(control,cond1,cond2),names_to="condition",values_to="measurement")
print(datLong)
```

**Long to wide:** `pivot_wider()`

```{r, collapse=T}
pivot_wider(data=datLong,names_from=condition,values_from=measurement)
```

Notes:

* If you have longitudinal data with variable time points, you can only use the long format.
* The base R package `stats` also provides a function that allows switching between logn and wide formats: `reshape()`. You can explore this function by yourself (type `?reshape` at the R console to open the documentation page for it), but generally the use of `pivot_longer()` and `pivot_wider()` is more intuitive.


### Coding 

#### R scripts

When you develop code for an analysis, this will often be a lengthy set of R commands. To access this as you develop the code, it is best to save the analysis code in a script file.

In RStudio, click on `File`, then `New File` and then `R Script`. In the script editor a new, blank script will open. This is just a text file that can hold your R code. You can save this to disk like any other file. You could use a `.txt` extension, but typically R scripts are saved as `.R` files.

In general:

* Experiment with code on the console.
* Save the code you want to keep in a script file using the script editor.

#### R functions

When you need to do a given set of commands over and over again, it may be more efficient to group them in an R function - it avoids you to write repetitive code.

To define a function you need to use the R function `function()`. Inside the brackets you then specify the input arguments to the function you define. The body of code for the function follows in curly brackets after the call to `function`.

Below is an example where we define a new function, `summaryFunction()`, that will compute the mean and standard deviation of a specific variable in a data frame and returns this as a list of length 2.

```{r}
summaryFunction<-function(dat,var){
  # dat = a data frame
  # var = a character string indicating the name of the variable in the dat data frame that is to be summarised
  
  m<-mean(dat[,var])
  s<-sd(dat[,var])
  
  return(list(mean=m,sd=s))
}

summaryFunction(dat=iris,var="Sepal.Width")
```

#### Iterations and control statements: *for* loops and *if* statements

A key concept in most programming languages are mechanisms to iterate a set of instructions and to control the execution of parts of the code. There are many of these in R, but we will focus on 2 key concepts here:

* *for* loops - to iterate a section of code over a vector, data frame or list

* *if* statement - to write sections of code that are only run conditional on certain condition(s) to be met

```{r}
# create an empty vector of the desired size
flowerSize<-rep(NA,nrow(iris))

# iterate over all rows of the iris data frame
for(i in 1:nrow(iris)){
  flowerSize[i]<-iris$Petal.Length[i]+iris$Petal.Width[i]+iris$Sepal.Length[i]+iris$Sepal.Width[i]
}

irisNew2<-cbind(iris,flowerSize)

head(irisNew)
```

*for* loops are slow in R. Whenever possible, attempt to *vectorise* your operations.

```{r}
# what we've just done
forLoop<-function(){
    flowerSize<-rep(NA,nrow(iris))
  
  for(i in 1:nrow(iris)){
    flowerSize[i]<-iris$Petal.Length[i]+iris$Petal.Width[i]+iris$Sepal.Length[i]+iris$Sepal.Width[i]
  }
}

# same operation but vectorised
vectorOperation<-function(){
  flowerSize<-iris$Petal.Length+iris$Petal.Width+iris$Sepal.Length+iris$Sepal.Width
}

system.time(forLoop())
system.time(vectorOperation())
```

## Parameter estimation / summary statistics (primer)

### Proportions

The function `binom.test()` allows you to easily compute proportion estimates and exact binomial 95% confidence intervals:

```{r props}
propEst<-binom.test(x=sum(dat$Species=="setosa"),n=nrow(dat))
propEst$estimate
propEst$conf.int
```

Formatting this nicely and expressing it as percentages:

```{r propsFormat}
propNice<-paste(sep="",
                format(nsmall=1,round(digits=1,100*propEst$estimate)),
                "% (",
                format(nsmall=1,round(digits=1,100*propEst$conf.int[1])),
                "%, ",
                format(nsmall=1,round(digits=1,100*propEst$conf.int[2])),
                "%)")

cat(propNice,file="")
```

### Means, standard deviations:

To compute an arithmetic mean, the R function `mean()` can be used and for standard deviations the function `sd()` is used.

```{r means}
mu<-mean(dat$Petal.Length,na.rm=TRUE)
sigma<-sd(dat$Petal.Length,na.rm=TRUE)
sigma2<-sigma^2 # same as sigma2<-var(dat$Petal.Length,na.rm=TRUE)
n<-sum(!is.na(dat$Petal.Length))

ci<-c(
  mu - qnorm(0.975)*sigma/sqrt(n),
  mu + qnorm(0.975)*sigma/sqrt(n)
)

print(mu)
print(sigma)
print(sigma^2)
print(ci)
```

### Medians, interquartile ranges:

To compute a median, the function `median()` is used and for IQRs, use `quantile()`. You can also use the function `iqr()` for the latter but this returns the width of the IQR.

```{r medians}
me<-median(dat$Petal.Length,na.rm=TRUE)
iqr<-quantile(dat$Petal.Length,probs=c(0.25,0.75),na.rm=TRUE)

print(me)
print(iqr)
```

### Grouping & summarising

Often it is easiest to summarise a dataset, when you group observations. The R functions `group_by()` and `summarise()` are useful here.

```{r summarise}
dat %>%
  group_by(Species) %>%
  summarise(
    mean=mean(Petal.Length),
    median=median(Petal.Length),
    sd=sd(Petal.Length),
    q25=quantile(Petal.Length,probs=0.25),
    q75=quantile(Petal.Length,probs=0.75)
    ,.groups="drop")
```

